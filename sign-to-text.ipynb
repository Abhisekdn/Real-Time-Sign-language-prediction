{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44d332-f2f9-4a3f-9773-06acd32fbc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fce4a2b-5a16-4076-84ad-a431095124d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello wolrd\n"
     ]
    }
   ],
   "source": [
    "print(\"hello wolrd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebfc204-9a92-473a-873a-72fe72968d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ab19c-e0d9-48b5-9006-b7187715f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c345bb-a125-41fd-b934-27efda875f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5688004a-d1fd-4aa1-9036-d099bb1c3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting scipy>=0.14\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-macosx_10_9_x86_64.whl (28.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.8 MB 8.6 MB/s eta 0:00:01    |█████▉                          | 5.2 MB 7.9 MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /Users/doddaballapurabhishek/opt/anaconda3/envs/major_/lib/python3.6/site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: h5py in /Users/doddaballapurabhishek/opt/anaconda3/envs/major_/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp36-cp36m-macosx_10_9_x86_64.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/doddaballapurabhishek/opt/anaconda3/envs/major_/lib/python3.6/site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: scipy, pyyaml, keras\n",
      "Successfully installed keras-2.4.3 pyyaml-5.4.1 scipy-1.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc49acb4-1779-4e2f-8797-32e94feeeb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import operator\n",
    "import cv2\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55d9557-ee48-458b-b2e5-12e1d5ff0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test/A/109.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5417e2-006d-42c6-af7a-09d46d144bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"img\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e764d8-be08-4ee7-9330-702e1f55e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Loading the model\n",
    "\n",
    "json_file = open(\"model(google_abhi_1)-bw.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model(google_abhi_1w)-bw.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cddf718-05fb-46a7-af1c-e742eb555bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='model(google_abhi_1)-bw.json' mode='r' encoding='UTF-8'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c62a55-3459-4c2d-864e-53bdfc76752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x107565ac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f4b2e9e-ad70-4bb3-8638-f7931c0b3422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 128, 128, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv2d_input\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d\", \"trainable\": true, \"batch_input_shape\": [null, 128, 128, 1], \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 32, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"MaxPooling2D\", \"config\": {\"name\": \"max_pooling2d_1\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.4, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 96, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout_1\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.4, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 64, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_3\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 27, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ffea4-2083-4932-99b3-9275429d5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Category dictionary\n",
    "categories = {0: 'ZERO ', 'A': 'a', 'B': 'b', 'C': 'c', 'D': 'd', 'E': 'e','F':'f','G':'g','H':'h','I':'i','J':'j','K':'k','L':'l','M':'m','N':'n','O':'o','P':'p','Q':'q','R':'r','S':'s','T':'t','U':'u','V':'v','W':'w','X':'x','Y':'y','Z':'z'}\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    # Simulating mirror image\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Got this from collect-data.py\n",
    "    # Coordinates of the ROI\n",
    "    x1 = int(0.5*frame.shape[1])\n",
    "    y1 = 10\n",
    "    x2 = frame.shape[1]-10\n",
    "    y2 = int(0.5*frame.shape[1])\n",
    "    # Drawing the ROI\n",
    "    # The increment/decrement by 1 is to compensate for the bounding box\n",
    "    cv2.rectangle(frame, (x1-1, y1-1), (x2+1, y2+1), (255,0,0) ,1)\n",
    "    # Extracting the ROI\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resizing the ROI so it can be fed to the model for prediction\n",
    "    roi = cv2.resize(roi, (128, 128)) \n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, test_image = cv2.threshold(roi, 120, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"test\", test_image)\n",
    "    # Batch of 1\n",
    "    result = loaded_model.predict(test_image.reshape(1, 128, 128, 1))\n",
    "    prediction = {'ZERO': result[0][0], \n",
    "                  'a': result[0][1], \n",
    "                  'b': result[0][2],\n",
    "                  'c': result[0][3],\n",
    "                  'd': result[0][4],\n",
    "                  'e': result[0][5],\n",
    "                  'f': result[0][6],\n",
    "                  'g': result[0][7],\n",
    "                  'h': result[0][8],\n",
    "                  'i': result[0][9],\n",
    "                  'j': result[0][10],\n",
    "                  'k': result[0][11],\n",
    "                  'l': result[0][12],\n",
    "                  'm': result[0][13],\n",
    "                  'n': result[0][14],\n",
    "                  'o': result[0][15],\n",
    "                  'p': result[0][16],\n",
    "                  'q': result[0][17],\n",
    "                  'r': result[0][18],\n",
    "                  's': result[0][19],\n",
    "                  't': result[0][20],\n",
    "                  'u': result[0][21],\n",
    "                  'v': result[0][22],\n",
    "                  'w': result[0][23],\n",
    "                  'x': result[0][24],\n",
    "                  'y': result[0][25],\n",
    "                  'z': result[0][26]\n",
    "                  }\n",
    "    # Sorting based on top prediction\n",
    "    prediction = sorted(prediction.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    # Displaying the predictions\n",
    "    cv2.putText(frame, prediction[0][0], (10, 120), cv2.FONT_HERSHEY_PLAIN, 1, (0,255,255), 1)    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    \n",
    "    interrupt = cv2.waitKey(10)\n",
    "    if interrupt & 0xFF == 27: # esc key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c558d-4b68-495f-9d1a-2a64569f8225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
